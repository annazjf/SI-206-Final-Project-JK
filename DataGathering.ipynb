{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Setup\n","api_key = open('alpha_vantage_apikey.txt').read()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 1. Company's time series data\n","Get time series data from representative companies in different industry, using API, store in separate json files"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import json\n","import requests\n","def make_company_json(company_stock_name):\n","    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={company_stock_name}&apikey={api_key}'\n","\n","    # Send the API request and retrieve the response\n","    response = requests.get(url)\n","    data = response.json()\n","    fileName = company_stock_name + '.json'\n","    with open(fileName, 'w') as f:\n","        json.dump(data[\"Time Series (Daily)\"], f)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Information Technology - AAPL (APPLE), MSFT(MICROSOFT)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["make_company_json('AAPL')\n","make_company_json('MSFT')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Energy -  Exxon Mobil (XOM), Chevron (CVX)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["make_company_json('XOM')\n","make_company_json('CVX')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Health Care - Johnson & Johnson (JNJ), Eli Lilly & Co. (LLY) "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["make_company_json('JNJ')\n","make_company_json('LLY')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Convert json to db"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import os\n","import sqlite3\n","def read_data(filename):\n","    current_folder = globals()['_dh'][0]\n","    full_path = os.path.join(current_folder, filename)\n","    f = open(full_path)\n","    file_data = f.read()\n","    f.close()\n","    json_data = json.loads(file_data)\n","    return json_data\n","def open_database(db_name):\n","    current_folder = globals()['_dh'][0]\n","    full_path = os.path.join(current_folder, db_name)\n","    conn = sqlite3.connect(full_path)\n","    cur = conn.cursor()\n","    return cur, conn\n","\n","company_list = ['AAPL','MSFT','CVX','XOM', 'JNJ','LLY']\n","json_data = {}\n","for company in company_list:\n","    json_data[company] = read_data(company + '.json')\n","cur, conn = open_database('company_stock.db')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Load all json file into database, under company.db\n","Insert 25 rows each time, {id, date, closing stock price}"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["for company in company_list:\n","    query = f\"DROP TABLE IF EXISTS {company}\"\n","    cur.execute(query)\n","conn.commit()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def make_stock_close_tb(data, cur, conn,company):\n","    # store date and close price into a list\n","    dateL,closeL = [],[]\n","    for date in data:\n","        dateL.append(date)\n","        closeL.append(data[date][\"4. close\"])\n","    # Check if the Company table exist\n","    query = f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{company}'\"\n","    cur.execute(query)\n","    table_exists = cur.fetchone() is not None\n","\n","    if table_exists:\n","        # if the table exists \n","        # dates are being inserted in reverse order (most recent date = 1st row)\n","        query = f\"SELECT MIN(date) FROM {company}\"\n","        cur.execute(query)\n","        most_not_recent_date = cur.fetchone()[0]\n","        startIndex = dateL.index(most_not_recent_date) + 1\n","    else:\n","        startIndex = 0\n","\n","    #Create the table and insert approapriate data\n","    createTB = f\"CREATE TABLE IF NOT EXISTS {company} (id INTEGER PRIMARY KEY, date DATE UNIQUE, close DOUBLE)\"\n","    cur.execute(createTB)\n","    #Insert 25 rows at a time\n","    for i in range(startIndex,min(startIndex+25,100)):\n","        query = f\"INSERT OR IGNORE INTO {company} (id, date, close) VALUES (?,?,?)\"\n","        cur.execute(query, (i + 1, dateL[i], closeL[i]))\n","    conn.commit()\n","\n","\n","for company in company_list:\n","    make_stock_close_tb(json_data[company],cur,conn,company)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 2.S&P Index\n","Using Yahoo API and downloaded a year s&p index csv file, convert to data base"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import yfinance as yf\n","import pandas as pd\n","\n","sp500 = yf.Ticker('^GSPC')\n","sp500_hist = sp500.history(period='6mo')\n","sp500_hist = sp500_hist.sort_values(by='Date', ascending=False)\n","sp500_hist.to_csv('sp500_6m.csv',index_label=None)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["<sqlite3.Cursor at 0x1231632d0>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["cur.execute(\"DROP TABLE IF EXISTS SP500\")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import csv\n","\n","# Check if the table exists\n","cur.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='SP500'\")\n","table_exists = cur.fetchone() is not None\n","idx = 0\n","if table_exists:\n","    # If the table exists, find the row number of the most recent date\n","    cur.execute(\"SELECT MIN(date) FROM SP500\")\n","    most_not_recent_date2 = cur.fetchone()[0]\n","    for date in sp500_hist.index:\n","        if (str(date)[:10] == most_not_recent_date2[:10]):\n","            idx = sp500_hist.index.get_loc(date) + 1\n","            break\n","cur.execute(\"CREATE TABLE IF NOT EXISTS SP500 (date DATE UNIQUE, close DOUBLE)\")\n","\n","# Read the CSV file and insert the remaining rows into the database\n","with open('sp500_6m.csv', 'r') as f:\n","    reader = csv.reader(f)\n","    next(reader)  # Skip the header row\n","    i = 0\n","    for row in reader:\n","        if i >= idx:\n","            cur.execute(\"INSERT OR IGNORE INTO SP500 (date, close) VALUES (?,?)\",(row[0][:10],row[4]))\n","        if i == idx + 24:\n","            break\n","        i += 1\n","\n","# Commit changes and close the database connection\n","conn.commit()"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
